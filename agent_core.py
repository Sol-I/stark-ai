from openai import OpenAI
import logging
import asyncio
from config import OPENROUTER_API_KEY, MODEL_RANKING

logging.basicConfig(level=logging.WARNING)

class AIAgent:
    def __init__(self, api_key: str = OPENROUTER_API_KEY):
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
        )
        self.conversations = {}
        self.max_history = 3
        self.model_ranking = MODEL_RANKING
        self.current_model_index = 0
        self.available_models = set()
        
    async def check_model_availability(self, model_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏"""
        try:
            test_message = [{"role": "user", "content": "test"}]
            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "http://94.228.123.86:8000",
                    "X-Title": "Stark AI",
                },
                model=model_name,
                messages=test_message,
                max_tokens=10
            )
            return True
        except Exception:
            return False
    
    async def find_best_available_model(self) -> str:
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å"""
        for i, model in enumerate(self.model_ranking):
            if await self.check_model_availability(model["name"]):
                self.current_model_index = i
                print(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ –º–æ–¥–µ–ª—å: {model['name']} ({model['params']}B)")
                return model["name"]
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–∞–±–æ—Ç–∞—é—â—É—é
        return self.model_ranking[-1]["name"]
    
    async def process_message(self, user_id: str, message: str) -> str:
        if user_id not in self.conversations:
            self.conversations[user_id] = []
        
        current_history = self.conversations[user_id][-self.max_history:]
        current_history.append({"role": "user", "content": message})
        
        try:
            current_model = self.model_ranking[self.current_model_index]
            
            # –ü—Ä–æ–±—É–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
            try:
                completion = self.client.chat.completions.create(
                    extra_headers={
                        "HTTP-Referer": "http://94.228.123.86:8000",
                        "X-Title": "Stark AI",
                    },
                    model=current_model["name"],
                    messages=current_history,
                    max_tokens=1024
                )
                
                ai_response = completion.choices[0].message.content
                model_info = f"\n\n---\n*–û—Ç–≤–µ—á–∞–µ—Ç {current_model['provider']} ({current_model['params']}B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)*"
                
            except Exception:
                # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—â–µ–º –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
                best_model_name = await self.find_best_available_model()
                best_model = self.model_ranking[self.current_model_index]
                
                completion = self.client.chat.completions.create(
                    extra_headers={
                        "HTTP-Referer": "http://94.228.123.86:8000", 
                        "X-Title": "Stark AI",
                    },
                    model=best_model_name,
                    messages=current_history,
                    max_tokens=1024
                )
                
                ai_response = completion.choices[0].message.content
                model_info = f"\n\n---\n*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ {best_model['provider']} ({best_model['params']}B)*"
            
            current_history.append({"role": "assistant", "content": ai_response})
            self.conversations[user_id] = current_history[-self.max_history:]
            
            return ai_response + model_info
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"
    
    async def background_model_checker(self):
        """–§–æ–Ω–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        while True:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π —Å –≤—ã—Å–æ–∫–∏–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º
                for i in range(3):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ø-3 –º–æ–¥–µ–ª–∏
                    if i != self.current_model_index and await self.check_model_availability(self.model_ranking[i]["name"]):
                        if i < self.current_model_index:  # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –º–æ–¥–µ–ª—å –ª—É—á—à–µ —Ç–µ–∫—É—â–µ–π
                            self.current_model_index = i
                            print(f"üéØ –í–µ—Ä–Ω—É–ª—Å—è –∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {self.model_ranking[i]['name']}")
                            break
                
                await asyncio.sleep(300)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
            except Exception:
                await asyncio.sleep(60)
    
    def clear_history(self, user_id: str):
        if user_id in self.conversations:
            del self.conversations[user_id]
